#!/usr/bin/env python
PACKAGE = "descriptor_surface_based_recognition"

from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

gen.add("medianPointsOffset", int_t, 0, "Offset of the points used for calculating the median point the point cloud reduction relies on.", 3, 1, 100)
gen.add("samplingDistance", double_t, 0, "Scene sampling distance relative to the diameter of the surface model used in 3D recognition.", 0.04, 0.01, 0.99)
gen.add("keypointFraction", double_t, 0, "Fraction of sampled scene points used as key points in 3D recognition.", 0.4, 0.01, 0.99)
gen.add("useVisualisationColor", bool_t, 0, "Use a colorized image for the visualisation of the 2D recognition.", False) 
gen.add("visualisationColorPointsRed", int_t, 0, "Red component of the visualized points' color.", 0, 0, 255) 
gen.add("visualisationColorPointsGreen", int_t, 0, "Green component of the visualized points' color.", 255, 0, 255) 
gen.add("visualisationColorPointsBlue", int_t, 0, "Blue component of the visualized points' color.", 255, 0, 255) 
gen.add("visualisationColorBoxRed", int_t, 0, "Red component of the visualized bounding box color.", 255, 0, 255) 
gen.add("visualisationColorBoxGreen", int_t, 0, "Green component of the visualized bounding box color.", 0, 0, 255) 
gen.add("visualisationColorBoxBlue", int_t, 0, "Blue component of the visualized bounding box color.", 0, 0, 255) 
gen.add("boundingBoxBorderSize", int_t, 0, "Thickness of the visualized bounding box.", 3, 1, 20) 
gen.add("orientationTriangleSize", int_t, 0, "Size of the triangle visualizing the orientation of the bounding box.", 10, 1, 50)
gen.add("featurePointsRadius", int_t, 0, "Radius of the visualized feature points.", 2, 1, 10)

gen.add("drawCloudBoxes", bool_t, 0, "Draw bounding boxes, each containing the 3D search domain for a found object instance.", True) 
gen.add("drawCompleteCloudBoxes", bool_t, 0, "Draw a complete bounding box (only the front side if false)", True)

gen.add("usePoseValidation", bool_t, 0, "Validate found poses by comparing the input RGB-image to a rendered one with the found objects", False) 
gen.add("poseValidationDistanceError", int_t, 0, "Maximum distance between two points which where projected with the found projection matrix in the original image and the one in the rendered image", 15, 1, 500)
gen.add("aggressivePoseValidation", bool_t, 0, "Discard a pose if no view can be found in the rendered image. If disabled a pose is set as valid when no view was found", True) 

gen.add("evaluation", bool_t, 0, "Output evaluation files (runtimes and found poses)", False) 


exit(gen.generate(PACKAGE, "descriptor_surface_based_recognition", "DescriptorSurfaceBasedRecognition"))
